import json
import logging
import cv2
import torch
import base64
import numpy as np
import mediapipe as mp
import asyncio
from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from ultralytics import YOLO
from models.predict import predict_focus
import time

# âœ… Logger ì„¤ì •
logger = logging.getLogger(__name__)
logging.getLogger("ultralytics").setLevel(logging.ERROR)

router = APIRouter()

# âœ… YOLOv8 ëª¨ë¸ ë¡œë“œ (í•¸ë“œí° ê°ì§€)
device = "cuda" if torch.cuda.is_available() else "cpu"
yolo_model = YOLO("yolov8s.pt", verbose=False).to(device)
logger.info("âœ… YOLOv8s ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# âœ… Mediapipe Pose & Face Mesh ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
mp_face_mesh = mp.solutions.face_mesh
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)

def extract_body_landmarks(pose_landmarks):
    """ìƒì²´ ê´€ì ˆ ì¢Œí‘œë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”í•˜ì—¬ ë°˜í™˜"""
    if pose_landmarks is None:
        return None
    
    return {
        "head_x": pose_landmarks[0].x, "head_y": pose_landmarks[0].y,
        "neck_x": pose_landmarks[1].x, "neck_y": pose_landmarks[1].y,
        "shoulder_left_x": pose_landmarks[11].x, "shoulder_left_y": pose_landmarks[11].y,
        "shoulder_right_x": pose_landmarks[12].x, "shoulder_right_y": pose_landmarks[12].y,
        "elbow_left_x": pose_landmarks[13].x, "elbow_left_y": pose_landmarks[13].y,
        "elbow_right_x": pose_landmarks[14].x, "elbow_right_y": pose_landmarks[14].y,
        "wrist_left_x": pose_landmarks[15].x, "wrist_left_y": pose_landmarks[15].y,
        "wrist_right_x": pose_landmarks[16].x, "wrist_right_y": pose_landmarks[16].y
    }

def compute_head_tilt(pose_landmarks):
    """ê³ ê°œ ê¸°ìš¸ê¸° ê³„ì‚°"""
    if pose_landmarks is None:
        return None
    return abs(pose_landmarks[0].y - pose_landmarks[1].y)

def compute_eye_direction(face_landmarks):
    """ì‹œì„  ë°©í–¥ ë¶„ì„"""
    if face_landmarks is None:
        return None
    left_eye = face_landmarks[33].y
    right_eye = face_landmarks[263].y
    left_mouth = face_landmarks[61].y
    right_mouth = face_landmarks[291].y
    return abs(left_eye - left_mouth) + abs(right_eye - right_mouth)

def detect_phone(frame):
    """YOLOv8ì„ ì‚¬ìš©í•˜ì—¬ í•¸ë“œí° ê°ì§€"""
    results = yolo_model(frame, conf=0.3)
    for result in results:
        for box in result.boxes:
            class_id = int(box.cls)
            if class_id == 67:
                return 1  # ğŸ“± í•¸ë“œí° ê°ì§€ë¨
    return 0  # âŒ í•¸ë“œí° ë¯¸ê°ì§€

@router.websocket("/focus")
async def focus_websocket(websocket: WebSocket):
    await websocket.accept()
    logger.info("âœ… WebSocket ì—°ê²°ë¨")

    try:
        while True:
            start_time = time.time()

            # ğŸ”¥ 1ì´ˆ ë™ì•ˆì˜ í”„ë ˆì„ ë°ì´í„° ì €ì¥ ë²„í¼ (ì´ˆê¸°í™”)
            frame_data = []
            phone_detected_history = []
            head_tilt_history = []
            eye_direction_history = []

            # âœ… í”„ë¡ íŠ¸ì—ì„œ `frames: []` í˜•ì‹ìœ¼ë¡œ ì „ì†¡ë¨ -> ì´ë¥¼ ë°›ì•„ì„œ ì²˜ë¦¬
            data = await websocket.receive_json()
            frames = data.get("frames", [])

            if not frames:
                logger.error("âŒ WebSocket ë°ì´í„° ì˜¤ë¥˜: frames ë°°ì—´ì´ ë¹„ì–´ ìˆìŒ")
                continue

            for frame_index, base64_frame in enumerate(frames):
                try:
                    # âœ… Base64ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜
                    frame_data_bytes = base64.b64decode(base64_frame)
                    np_arr = np.frombuffer(frame_data_bytes, np.uint8)
                    frame = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

                    if frame is None:
                        logger.error("âŒ OpenCVì—ì„œ í”„ë ˆì„ì„ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                        continue

                    # âœ… YOLOv8 í•¸ë“œí° ê°ì§€ ì‹¤í–‰ (ì›ë³¸ í•´ìƒë„ ìœ ì§€)
                    phone_detected = detect_phone(frame)
                    phone_detected_history.append(phone_detected)

                    # âœ… Mediapipe í¬ì¦ˆ ë¶„ì„
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results_pose = pose.process(frame_rgb)
                    results_face = face_mesh.process(frame_rgb)

                    # âœ… í¬ì¦ˆ ë¶„ì„ ê²°ê³¼ ì €ì¥
                    body_landmarks = extract_body_landmarks(results_pose.pose_landmarks.landmark if results_pose.pose_landmarks else None)
                    head_tilt = compute_head_tilt(results_pose.pose_landmarks.landmark if results_pose.pose_landmarks else None)
                    eye_direction = compute_eye_direction(results_face.multi_face_landmarks[0].landmark if results_face.multi_face_landmarks else None)

                    head_tilt_history.append(head_tilt)
                    eye_direction_history.append(eye_direction)

                    frame_data.append({
                        "frame_index": frame_index,
                        **(body_landmarks if body_landmarks else {}),
                        "head_tilt": head_tilt if head_tilt is not None else 0,
                        "eye_direction": eye_direction if eye_direction is not None else 0,
                        "phone_detected": 1 if phone_detected else 0
                    })
                except Exception as e:
                    logger.error(f"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            # âœ… 1ì´ˆ ë™ì•ˆì˜ ë°ì´í„° í‰ê·  ê³„ì‚°
            phone_detected_percentage = 1 if any(phone_detected_history) else 0
            avg_head_tilt = sum(filter(None, head_tilt_history)) / len(head_tilt_history) if head_tilt_history else 0
            avg_eye_direction = sum(filter(None, eye_direction_history)) / len(eye_direction_history) if eye_direction_history else 0

            # âœ… 1ì´ˆ ë™ì•ˆì˜ ëª¨ë“  í”„ë ˆì„ì„ í¬í•¨í•œ payload ìƒì„±
            payload = {
                "frame_data": frame_data,  # ğŸ”¥ ì „ì²´ í”„ë ˆì„ ë°ì´í„° í¬í•¨
                "phone_detected_percentage": phone_detected_percentage,
                "head_tilt": avg_head_tilt,
                "eye_direction": avg_eye_direction
            }

            # âœ… AI ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰ (ğŸ”¥ ì§‘ì¤‘ë„ ë¶„ì„)
            prediction, confidence = predict_focus(payload)

            # âœ… WebSocketìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ì „ì†¡
            result = {
                "focus_prediction": prediction,
                "confidence": confidence,
                "phone_detected_percentage": phone_detected_percentage,
                "head_tilt": avg_head_tilt,
                "eye_direction": avg_eye_direction,
                "timestamp": int(time.time())
            }

            logger.info(f"ğŸ“¡ AI ì˜ˆì¸¡ ê²°ê³¼: {json.dumps(result, indent=2)}")
            await websocket.send_json(result)

    except WebSocketDisconnect:
        logger.info("ğŸ”´ í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ì„ ì¢…ë£Œí•¨")
    finally:
        await websocket.close()
