import { useEffect, useRef, useState } from "react";
import { Hands } from "@mediapipe/hands";
import { Camera } from "@mediapipe/camera_utils";
import { useSetRecoilState } from "recoil";
import { aiFocusState } from "../../../recoil/atoms/ai/aiState";

const FocusAnalysis = ({ serverUrl }) => {
    const socketRef = useRef(null);
    const canvasRef = useRef(document.createElement("canvas"));
    const videoRef = useRef(null);
    const frameBuffer = useRef([]); // âœ… í”„ë ˆì„ì„ ëª¨ì•„ë‘ëŠ” ë²„í¼
    const frameInterval = 100; // ğŸ”¥ 100ms (1ì´ˆì— 10í”„ë ˆì„ ìº¡ì²˜)
    const batchSize = 10; // âœ… 10ê°œì˜ í”„ë ˆì„ì„ ëª¨ì•„ í•œ ë²ˆì— ì „ì†¡
    const mediaStreamRef = useRef(null); // âœ… WebRTC ìŠ¤íŠ¸ë¦¼ ì¶”ì ìš©
    const intervalRef = useRef(null); // âœ… `setInterval` ì¶”ì ìš©
    const detectionTimeout = useRef(false); // âœ… íƒì§€ ì¼ì‹œ ì¤‘ì§€ ìƒíƒœ ì¶”ì 
    const setAiFocusValue = useSetRecoilState(aiFocusState);


    // âœ… ì†ë°”ë‹¥(âœ‹) & ë”°ë´‰(ğŸ‘) ê°ì§€ ìƒíƒœ ë³€ìˆ˜
    const [isThumbsUp, setIsThumbsUp] = useState(false);
    const [isPalmOpen, setIsPalmOpen] = useState(false);
    let studyTimer = 0;
    let studyAttitude = true;
    useEffect(() => {
        socketRef.current = new WebSocket(serverUrl);

        socketRef.current.onopen = () => {
            console.log("âœ… WebSocket ì—°ê²° ì„±ê³µ:", serverUrl);
            startWebRTCStream();
        };

        socketRef.current.onerror = (error) => console.error("âŒ WebSocket ì—ëŸ¬:", error);

        socketRef.current.onmessage = (event) => {
            try {
                if (studyAttitude === true) {
                    studyTimer += 1;
                }
                const data = JSON.parse(event.data);
                console.log("ğŸ“¡ ì§‘ì¤‘ë„ ë¶„ì„ ê²°ê³¼:", data.focus_prediction);
                setAiFocusValue(data.focus_prediction)
                if (data.focus_prediction == 1) {
                    studyAttitude = true;
                }
                else {
                    studyAttitude = false;
                }
                // console.log("ğŸ“Š ì‹ ë¢°ë„:", data.confidence);
                // console.log("ğŸ‘€ ì‹œì„  ë°©í–¥:", data.eye_direction);
                // console.log("ğŸ¤– ë¨¸ë¦¬ ê¸°ìš¸ê¸°:", data.head_tilt);
                // console.log(studyTimer)
                // console.log("----------------------------------------------------");
            } catch (error) {
                console.error("âŒ WebSocket ë°ì´í„° ì˜¤ë¥˜:", error);
            }
        };

        startHandTracking(); // âœ… ì† ë™ì‘ ê°ì§€ ì‹œì‘

        return () => {
            stopWebRTCStream();
            closeWebSocket();
            if (intervalRef.current) {
                clearInterval(intervalRef.current); // ì£¼ê¸°ì ì¸ ê°ì§€ ì¤‘ì§€
            }
        };
    }, [serverUrl]);

    // âœ… WebRTC ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘í•˜ëŠ” í•¨ìˆ˜
    const startWebRTCStream = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            mediaStreamRef.current = stream;
            videoRef.current.srcObject = stream;
            startFrameCapture();
        } catch (error) {
            console.error("âŒ WebRTC ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜:", error);
        }
    };

    // âœ… WebRTC ìŠ¤íŠ¸ë¦¼ì„ ì¤‘ì§€í•˜ëŠ” í•¨ìˆ˜
    const stopWebRTCStream = () => {
        if (mediaStreamRef.current) {
            mediaStreamRef.current.getTracks().forEach(track => track.stop());
            mediaStreamRef.current = null;
            if (videoRef.current) {
                videoRef.current.srcObject = null;
            }
            console.log("ğŸ”´ WebRTC ìŠ¤íŠ¸ë¦¼ì´ ì¤‘ì§€ë¨");
        }
    };

    // âœ… WebSocketì„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•˜ëŠ” í•¨ìˆ˜
    const closeWebSocket = () => {
        if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
            socketRef.current.close();
            console.log("ğŸ”´ WebSocketì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë¨");
        }
    };

    // âœ… ì¼ì • ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ì„ ìº¡ì²˜í•˜ì—¬ ë²„í¼ì— ì €ì¥
    const startFrameCapture = () => {
        intervalRef.current = setInterval(() => {
            captureFrame();
        }, frameInterval);
    };

    // âœ… í”„ë ˆì„ì„ ìº¡ì²˜í•˜ì—¬ ë²„í¼ì— ì €ì¥
    const captureFrame = () => {
        const videoElement = videoRef.current;
        if (!videoElement) return;

        const canvas = canvasRef.current;
        const context = canvas.getContext("2d");
        canvas.width = 640;
        canvas.height = 480;
        context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

        // ìº”ë²„ìŠ¤ë¥¼ Base64ë¡œ ë³€í™˜ í›„ ë²„í¼ì— ì €ì¥
        canvas.toBlob(
            (blob) => {
                if (blob) {
                    const reader = new FileReader();
                    reader.readAsDataURL(blob);
                    reader.onloadend = () => {
                        const base64Frame = reader.result.split(",")[1]; // Base64 ì¸ì½”ë”©
                        frameBuffer.current.push(base64Frame);

                        // âœ… ì¼ì • ê°œìˆ˜(batchSize)ë§Œí¼ ëª¨ì´ë©´ í•œ ë²ˆì— ì „ì†¡
                        if (frameBuffer.current.length >= batchSize) {
                            sendBufferedFrames();
                        }
                    };
                }
            },
            "image/jpeg",
            0.7
        );
    };

    // âœ… ëª¨ì¸ í”„ë ˆì„ì„ í•œ ë²ˆì— WebSocketìœ¼ë¡œ ì „ì†¡
    const sendBufferedFrames = () => {
        if (!socketRef.current || socketRef.current.readyState !== WebSocket.OPEN) {
            console.warn("âš ï¸ WebSocketì´ ë‹«í˜€ ìˆì–´ í”„ë ˆì„ì„ ì „ì†¡í•  ìˆ˜ ì—†ìŒ.");
            return;
        }

        // console.log(`ğŸ“¤ ${batchSize}ê°œ í”„ë ˆì„ í•œ ë²ˆì— ì „ì†¡ ì¤‘...`);

        // ğŸ”¥ JSONìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í•œ ë²ˆì— ì „ì†¡
        socketRef.current.send(JSON.stringify({ frames: frameBuffer.current }));

        // âœ… ì „ì†¡ í›„ ë²„í¼ ë¹„ìš°ê¸°
        frameBuffer.current = [];
    };

    // âœ… MediaPipe Handsë¥¼ ì´ìš©í•œ ì† ë™ì‘ ê°ì§€
    const startHandTracking = () => {
        const hands = new Hands({
            locateFile: (file) =>
                `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
        });

        hands.setOptions({
            maxNumHands: 2,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5,
        });

        hands.onResults((results) => {
            if (results.multiHandLandmarks.length === 0) {
                setIsThumbsUp(false);
                setIsPalmOpen(false);
                return;
            }

            results.multiHandLandmarks.forEach((landmarks) => {
                // âœ… ì—„ì§€ ì†ê°€ë½ì´ ë‹¤ë¥¸ ì†ê°€ë½ë³´ë‹¤ ìœ„ì— ìˆì„ ê²½ìš° -> ë”°ë´‰
                const isThumbsUpDetected =
                    landmarks[4].y < landmarks[3].y &&
                    landmarks[4].y < landmarks[2].y &&
                    landmarks[4].y < landmarks[1].y &&
                    landmarks[8].y > landmarks[6].y &&
                    landmarks[12].y > landmarks[10].y;

                // âœ… ëª¨ë“  ì†ê°€ë½ì´ í´ì ¸ ìˆìœ¼ë©´ -> ì†ë°”ë‹¥ í¼ì¹¨
                const isPalmOpenDetected =
                    landmarks[8].y < landmarks[6].y &&
                    landmarks[12].y < landmarks[10].y &&
                    landmarks[16].y < landmarks[14].y &&
                    landmarks[20].y < landmarks[18].y;

                setIsThumbsUp(isThumbsUpDetected);
                setIsPalmOpen(isPalmOpenDetected);

                if (isThumbsUpDetected) {
                    console.log("ğŸ‘ ë”°ë´‰!");
                    stopDetectionForSeconds(3); // ì† ê°ì§€ í›„ 3ì´ˆê°„ ë¹„í™œì„±í™”
                } else if (isPalmOpenDetected) {
                    console.log("âœ‹ ì†ë°”ë‹¥!");
                    stopDetectionForSeconds(3); // ì† ê°ì§€ í›„ 3ì´ˆê°„ ë¹„í™œì„±í™”
                }
            });
        });

        // âœ… ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì™€ ê°ì§€
        if (videoRef.current) {
            const camera = new Camera(videoRef.current, {
                onFrame: async () => {
                    if (!detectionTimeout.current) {
                        await hands.send({ image: videoRef.current });
                    }
                },
                width: 640,
                height: 480,
            });
            camera.start();
        }

        // âœ… 1ì´ˆë§ˆë‹¤ ì† ê°ì§€ ì‹¤í–‰
        setInterval(() => {
            if (!detectionTimeout.current && videoRef.current) {
                hands.send({ image: videoRef.current });
            }
        }, 1000); // 1ì´ˆì— í•œë²ˆì”© ì† ê°ì§€ ì‹œë„
    };

    // âœ… ì† ê°ì§€ í›„ ì¼ì • ì‹œê°„(3ì´ˆ) ë™ì•ˆ ê°ì§€ë¥¼ ë¹„í™œì„±í™”
    const stopDetectionForSeconds = (seconds) => {
        detectionTimeout.current = true;
        console.log(`â¸ï¸ ${seconds}ì´ˆ ë™ì•ˆ ì† ê°ì§€ ë¹„í™œì„±í™”...`);
        setTimeout(() => {
            detectionTimeout.current = false;
            console.log("âœ… ì† ê°ì§€ ë‹¤ì‹œ í™œì„±í™”!");
        }, seconds * 1000);
    };

    return <video ref={videoRef} autoPlay playsInline style={{ display: "none" }} />;
};

export default FocusAnalysis;
